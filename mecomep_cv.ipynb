{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow import keras\n",
    "from scipy.interpolate import interpn\n",
    "from tqdm import tqdm\n",
    "from joblib import dump, load\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 25 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\A070050\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from load_data import process_steel_data\n",
    "\n",
    "full_path = 'data/'\n",
    "path = 'data/MDC_Data_Descriptions_MeCoMeP-r-value.xlsx'\n",
    "correlation_rate = 0.2\n",
    "dvl_line = 1\n",
    "\n",
    "df = process_steel_data(full_path, path, correlation_rate, dvl_line, model_output=True)\n",
    "df = pd.get_dummies(df, columns=['steel_family'], prefix='steel').drop(['steel_grade'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_cv_gridsearch(df, model, param_grid=None, n_splits=5, random_state=42, use_grid_search=True, model_params=None):\n",
    "    \"\"\"\n",
    "    Train a model with optional grid search and cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe\n",
    "    model : estimator object\n",
    "        Machine learning model to train\n",
    "    param_grid : dict, optional\n",
    "        Parameter grid for grid search (used if use_grid_search=True)\n",
    "    n_splits : int, optional\n",
    "        Number of cross-validation splits (default: 5)\n",
    "    random_state : int, optional\n",
    "        Random state for reproducibility (default: 42)\n",
    "    use_grid_search : bool, optional\n",
    "        Whether to perform grid search (default: True)\n",
    "    model_params : dict, optional\n",
    "        Direct model parameters to use if use_grid_search=False\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict containing model results and performance metrics including tol90\n",
    "    \"\"\"\n",
    "    # Prepare X and y\n",
    "    X = df.drop(['r_value'], axis=1)\n",
    "    y = df['r_value']\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Initialize metrics storage\n",
    "    cv_scores = {\n",
    "        'mae': [],\n",
    "        'mse': [],\n",
    "        'r2': [],\n",
    "        'tol90': []  # Add tol90 metric\n",
    "    }\n",
    "    \n",
    "    # Determine model parameters\n",
    "    if use_grid_search:\n",
    "        if param_grid is None:\n",
    "            raise ValueError(\"param_grid must be provided when use_grid_search is True\")\n",
    "        \n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=n_splits,\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearchCV\n",
    "        print(\"Performing GridSearch...\")\n",
    "        grid_search.fit(X, y)\n",
    "        print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        # Use directly specified parameters or default model\n",
    "        if model_params:\n",
    "            best_model = type(model)(**model_params)\n",
    "        else:\n",
    "            best_model = model\n",
    "        \n",
    "        grid_search = None\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    print(\"\\nPerforming cross-validation...\")\n",
    "    pbar = tqdm(enumerate(kf.split(X), 1),\n",
    "                total=n_splits,\n",
    "                desc=\"Cross-validation\",\n",
    "                leave=True)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in pbar:\n",
    "        # Split data\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        \n",
    "        # Calculate tol90 (90th percentile of absolute errors)\n",
    "        abs_errors = np.abs(y_val - y_pred)\n",
    "        tol90 = np.percentile(abs_errors, 90)\n",
    "        \n",
    "        cv_scores['mae'].append(mae)\n",
    "        cv_scores['mse'].append(mse)\n",
    "        cv_scores['r2'].append(r2)\n",
    "        cv_scores['tol90'].append(tol90)\n",
    "        \n",
    "        # Update progress bar description\n",
    "        pbar.set_description(\n",
    "            f\"Fold {fold} - MAE: {mae:.4f}, MSE: {mse:.4f}, R2: {r2:.4f}, TOL90: {tol90:.4f}\"\n",
    "        )\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'model': best_model,\n",
    "        'best_params': grid_search.best_params_ if use_grid_search else model_params or {},\n",
    "        'avg_mae': np.mean(cv_scores['mae']),\n",
    "        'std_mae': np.std(cv_scores['mae']),\n",
    "        'avg_mse': np.mean(cv_scores['mse']),\n",
    "        'std_mse': np.std(cv_scores['mse']),\n",
    "        'avg_r2': np.mean(cv_scores['r2']),\n",
    "        'std_r2': np.std(cv_scores['r2']),\n",
    "        'avg_tol90': np.mean(cv_scores['tol90']),  # Add average tol90\n",
    "        'std_tol90': np.std(cv_scores['tol90']),   # Add std of tol90\n",
    "        'cv_scores': cv_scores,\n",
    "        'grid_search_results': grid_search.cv_results_ if use_grid_search else None\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def report_cv_results(results):\n",
    "    print(\"\\nCross-Validation Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Best Parameters: {results['best_params']}\")\n",
    "    print(f\"Average MAE: {results['avg_mae']:.4f} ± {results['std_mae']:.4f}\")\n",
    "    print(f\"Average MSE: {results['avg_mse']:.4f} ± {results['std_mse']:.4f}\")\n",
    "    print(f\"Average R2: {results['avg_r2']:.4f} ± {results['std_r2']:.4f}\")\n",
    "    print(f\"Average TOL90: {results['avg_tol90']:.4f} ± {results['std_tol90']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_scaled_df, scaler = scale_data(train_df)\n",
    "binary_columns = [col for col in test_df.columns if col.startswith('steel_')]\n",
    "columns_to_scale = [col for col in test_df.columns if col not in binary_columns + ['r_value']]\n",
    "scaled_test_data = scaler.transform(test_df[columns_to_scale])\n",
    "test_scaled_df = pd.DataFrame(scaled_test_data, columns=columns_to_scale)\n",
    "for col in binary_columns:\n",
    "    test_scaled_df[col] = test_df[col].values\n",
    "if 'r_value' in test_df.columns:\n",
    "    test_scaled_df['r_value'] = test_df['r_value'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GridSearch...\n",
      "\n",
      "Best parameters: {'n_estimators': 350}\n",
      "\n",
      "Performing cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 0.0860, MSE: 0.0145, R2: 0.9573, TOL90: 0.1982: 100%|██████████| 5/5 [26:46<00:00, 321.38s/it]\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(random_state=42)\n",
    "rfr_param_grid = {\n",
    "    'n_estimators': [350]\n",
    "}\n",
    "\n",
    "rfr_results = train_model_with_cv_gridsearch(\n",
    "    df=train_scaled_df,\n",
    "    model=rfr,\n",
    "    param_grid=rfr_param_grid,\n",
    "    n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GridSearch...\n",
      "\n",
      "Best parameters: {'eta': 0.1, 'lambda': 0.1, 'max_depth': 8}\n",
      "\n",
      "Performing cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 0.0873, MSE: 0.0146, R2: 0.9571, TOL90: 0.1984: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'eta': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4],\n",
    "    'lambda': [0, 0.01, 0.1, 1, 10, 50],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "xgb_results = train_model_with_cv_gridsearch(\n",
    "    df=train_scaled_df,\n",
    "    model=xgb_model,\n",
    "    param_grid=xgb_param_grid,\n",
    "    n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 0.0940, MSE: 0.0163, R2: 0.9520, TOL90: 0.2071: 100%|██████████| 5/5 [56:41<00:00, 680.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "results_without_grid = train_model_with_cv_gridsearch(\n",
    "    df=train_scaled_df, \n",
    "    model=GaussianProcessRegressor(), \n",
    "    use_grid_search=False,\n",
    "    model_params={'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + WhiteKernel(noise_level=1)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GridSearch...\n",
      "\n",
      "Best parameters: {'leaf_size': 20, 'n_neighbors': 10, 'weights': 'distance'}\n",
      "\n",
      "Performing cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 0.1056, MSE: 0.0219, R2: 0.9356, TOL90: 0.2345: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': list(range(2, 15)),\n",
    "    'leaf_size': [20, 30, 40, 50],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "knn_results = train_model_with_cv_gridsearch(\n",
    "    df=train_scaled_df,\n",
    "    model=knn_model,\n",
    "    param_grid=knn_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_saved_model_architecture(saved_model_path, df, target_column='r_value', n_splits=5, \n",
    "                               epochs=100, batch_size=32, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform cross-validation using architecture and parameters from a saved model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    saved_model_path : str\n",
    "        Path to saved .h5 model file\n",
    "    df : pandas DataFrame\n",
    "        Input data\n",
    "    target_column : str\n",
    "        Name of target column\n",
    "    n_splits : int\n",
    "        Number of CV folds\n",
    "    epochs : int\n",
    "        Number of training epochs\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict containing CV metrics\n",
    "    \"\"\"\n",
    "    # Load saved model to get architecture and parameters\n",
    "    base_model = tf.keras.models.load_model(saved_model_path)\n",
    "    \n",
    "            # Get learning rate from saved model and convert to Python float\n",
    "    learning_rate = float(base_model.optimizer.learning_rate.numpy())\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df.drop([target_column], axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Storage for CV metrics\n",
    "    cv_scores = {\n",
    "        'mae': [],\n",
    "        'mse': [],\n",
    "        'r2': []\n",
    "    }\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    print(\"\\nPerforming cross-validation...\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\nFold {fold}/{n_splits}\")\n",
    "        \n",
    "        # Clear previous model from memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Convert to float32\n",
    "        X_train = np.array(X_train, dtype=np.float32)\n",
    "        y_train = np.array(y_train, dtype=np.float32)\n",
    "        X_val = np.array(X_val, dtype=np.float32)\n",
    "        y_val = np.array(y_val, dtype=np.float32)\n",
    "        \n",
    "        # Create new model with same architecture\n",
    "        model = tf.keras.models.clone_model(base_model)\n",
    "        \n",
    "        # Compile with same optimizer type and learning rate\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_absolute_error',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=1e-4\n",
    "        )\n",
    "        \n",
    "        # Create TF datasets\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        train_dataset = (train_dataset\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .repeat())\n",
    "        \n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        val_dataset = val_dataset.batch(batch_size)\n",
    "        \n",
    "        steps_per_epoch = len(X_train) // batch_size\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_val, verbose=0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        \n",
    "        cv_scores['mae'].append(mae)\n",
    "        cv_scores['mse'].append(mse)\n",
    "        cv_scores['r2'].append(r2)\n",
    "        \n",
    "        print(f\"Fold {fold} - MAE: {mae:.4f}, MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    results = {\n",
    "        'avg_mae': np.mean(cv_scores['mae']),\n",
    "        'std_mae': np.std(cv_scores['mae']),\n",
    "        'avg_mse': np.mean(cv_scores['mse']),\n",
    "        'std_mse': np.std(cv_scores['mse']),\n",
    "        'avg_r2': np.mean(cv_scores['r2']),\n",
    "        'std_r2': np.std(cv_scores['r2']),\n",
    "        'cv_scores': cv_scores\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelPropertiesANN:\n",
    "    def __init__(self, input_dim, target_column):\n",
    "        self.input_dim = input_dim\n",
    "        self.target_column = target_column\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.best_score = float('inf')\n",
    "\n",
    "    def build_model(self, config):\n",
    "        hidden_layers = config['layers']\n",
    "        learning_rate = config['learning_rate']\n",
    "        l2_strength = config['l2_regularization']\n",
    "        \n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Input(shape=(self.input_dim,)))\n",
    "        \n",
    "        for units, activation in hidden_layers:\n",
    "            model.add(keras.layers.Dense(\n",
    "                units=units,\n",
    "                activation=activation,\n",
    "                kernel_regularizer=keras.regularizers.l2(l2_strength)\n",
    "            ))\n",
    "        \n",
    "        model.add(keras.layers.Dense(1))\n",
    "        \n",
    "        lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=100,\n",
    "            decay_rate=0.9,\n",
    "            staircase=True\n",
    "        )\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=1.0),\n",
    "            loss='mean_absolute_error',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def generate_grid_configs(self, \n",
    "        layer_options=[(64, 'relu'), (128, 'relu'), (256, 'relu')],\n",
    "        layer_depths=[2, 3, 4],\n",
    "        learning_rates=[1e-2, 1e-3, 1e-4],\n",
    "        l2_regularization=[1e-3, 1e-4, 1e-5],\n",
    "        batch_sizes=[16, 32, 64]\n",
    "    ):\n",
    "        from itertools import product\n",
    "        grid_configs = []\n",
    "        \n",
    "        for depth in layer_depths:\n",
    "            for lr in learning_rates:\n",
    "                for l2_reg in l2_regularization:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        layer_combinations = list(product(layer_options, repeat=depth))\n",
    "                        for layers in layer_combinations:\n",
    "                            config = {\n",
    "                                'layers': layers,\n",
    "                                'learning_rate': lr,\n",
    "                                'l2_regularization': l2_reg,\n",
    "                                'batch_size': batch_size\n",
    "                            }\n",
    "                            grid_configs.append(config)\n",
    "        \n",
    "        return grid_configs\n",
    "\n",
    "    def grid_search(self, train_scaled_df, grid_configs=None, epochs=100, max_configs=None):\n",
    "        # Split training data into training and validation sets\n",
    "        train_data, val_data = train_test_split(train_scaled_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "        if grid_configs is None:\n",
    "            grid_configs = self.generate_grid_configs()\n",
    "        \n",
    "        X_train = train_data.drop([self.target_column], axis=1)\n",
    "        y_train = train_data[self.target_column]\n",
    "        X_val = val_data.drop([self.target_column], axis=1)\n",
    "        y_val = val_data[self.target_column]\n",
    "        \n",
    "        if max_configs:\n",
    "            grid_configs = grid_configs[:max_configs]\n",
    "        \n",
    "        results = []\n",
    "        for config in tqdm(grid_configs, desc=\"Training models\"):\n",
    "            tf.keras.backend.clear_session()\n",
    "            model = self.build_model(config)\n",
    "            batch_size = min(config['batch_size'], len(X_train))\n",
    "            \n",
    "            early_stopping = keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss', \n",
    "                patience=10, \n",
    "                restore_best_weights=True,\n",
    "                min_delta=1e-4\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                X_train = np.array(X_train, dtype=np.float32)\n",
    "                y_train = np.array(y_train, dtype=np.float32)\n",
    "                X_val = np.array(X_val, dtype=np.float32)\n",
    "                y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                train_dataset = (train_dataset\n",
    "                    .batch(batch_size, drop_remainder=True)\n",
    "                    .repeat())\n",
    "                \n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "                val_dataset = val_dataset.batch(batch_size)\n",
    "                \n",
    "                steps_per_epoch = len(X_train) // batch_size\n",
    "                \n",
    "                history = model.fit(\n",
    "                    train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                val_loss = model.evaluate(X_val, y_val, verbose=0)[0]\n",
    "                \n",
    "                result_entry = config.copy()\n",
    "                result_entry.update({'val_loss': val_loss})\n",
    "                results.append(result_entry)\n",
    "                \n",
    "                if val_loss < self.best_score:\n",
    "                    self.best_score = val_loss\n",
    "                    self.best_model = model\n",
    "                    self.best_params = config\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error with config {config}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return self.best_model, self.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "Epoch 1/100\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.2094 - mae: 0.1861 - mse: 0.0806 - val_loss: 0.1512 - val_mae: 0.1287 - val_mse: 0.0297\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1485 - mae: 0.1267 - mse: 0.0283 - val_loss: 0.1401 - val_mae: 0.1189 - val_mse: 0.0249\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1385 - mae: 0.1180 - mse: 0.0251 - val_loss: 0.1375 - val_mae: 0.1175 - val_mse: 0.0243\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1352 - mae: 0.1159 - mse: 0.0243 - val_loss: 0.1362 - val_mae: 0.1174 - val_mse: 0.0233\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1283 - mae: 0.1100 - mse: 0.0222 - val_loss: 0.1369 - val_mae: 0.1190 - val_mse: 0.0246\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1261 - mae: 0.1088 - mse: 0.0218 - val_loss: 0.1541 - val_mae: 0.1371 - val_mse: 0.0305\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1226 - mae: 0.1061 - mse: 0.0209 - val_loss: 0.1313 - val_mae: 0.1151 - val_mse: 0.0230\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1206 - mae: 0.1047 - mse: 0.0204 - val_loss: 0.1299 - val_mae: 0.1145 - val_mse: 0.0227\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1170 - mae: 0.1018 - mse: 0.0196 - val_loss: 0.1281 - val_mae: 0.1133 - val_mse: 0.0226\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1146 - mae: 0.1000 - mse: 0.0190 - val_loss: 0.1290 - val_mae: 0.1147 - val_mse: 0.0228\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1147 - mae: 0.1006 - mse: 0.0194 - val_loss: 0.1237 - val_mae: 0.1098 - val_mse: 0.0211\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1121 - mae: 0.0985 - mse: 0.0186 - val_loss: 0.1201 - val_mae: 0.1067 - val_mse: 0.0205\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1102 - mae: 0.0970 - mse: 0.0180 - val_loss: 0.1170 - val_mae: 0.1040 - val_mse: 0.0193\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1100 - mae: 0.0971 - mse: 0.0182 - val_loss: 0.1115 - val_mae: 0.0988 - val_mse: 0.0182\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1076 - mae: 0.0950 - mse: 0.0176 - val_loss: 0.1310 - val_mae: 0.1186 - val_mse: 0.0247\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1082 - mae: 0.0959 - mse: 0.0179 - val_loss: 0.1170 - val_mae: 0.1048 - val_mse: 0.0201\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1063 - mae: 0.0942 - mse: 0.0173 - val_loss: 0.1175 - val_mae: 0.1055 - val_mse: 0.0205\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1060 - mae: 0.0941 - mse: 0.0174 - val_loss: 0.1165 - val_mae: 0.1047 - val_mse: 0.0200\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1067 - mae: 0.0950 - mse: 0.0175 - val_loss: 0.1177 - val_mae: 0.1060 - val_mse: 0.0207\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.1044 - mae: 0.0929 - mse: 0.0169 - val_loss: 0.1121 - val_mae: 0.1006 - val_mse: 0.0190\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1036 - mae: 0.0922 - mse: 0.0167 - val_loss: 0.1105 - val_mae: 0.0991 - val_mse: 0.0182\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1024 - mae: 0.0911 - mse: 0.0162 - val_loss: 0.1098 - val_mae: 0.0986 - val_mse: 0.0181\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1030 - mae: 0.0918 - mse: 0.0167 - val_loss: 0.1089 - val_mae: 0.0977 - val_mse: 0.0179\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1023 - mae: 0.0912 - mse: 0.0164 - val_loss: 0.1090 - val_mae: 0.0980 - val_mse: 0.0180\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1008 - mae: 0.0898 - mse: 0.0159 - val_loss: 0.1103 - val_mae: 0.0993 - val_mse: 0.0183\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0998 - mae: 0.0889 - mse: 0.0155 - val_loss: 0.1070 - val_mae: 0.0961 - val_mse: 0.0172\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0997 - mae: 0.0888 - mse: 0.0156 - val_loss: 0.1075 - val_mae: 0.0966 - val_mse: 0.0176\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0994 - mae: 0.0885 - mse: 0.0155 - val_loss: 0.1083 - val_mae: 0.0975 - val_mse: 0.0178\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0984 - mae: 0.0875 - mse: 0.0152 - val_loss: 0.1074 - val_mae: 0.0966 - val_mse: 0.0177\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0987 - mae: 0.0879 - mse: 0.0153 - val_loss: 0.1069 - val_mae: 0.0962 - val_mse: 0.0175\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0989 - mae: 0.0882 - mse: 0.0156 - val_loss: 0.1056 - val_mae: 0.0948 - val_mse: 0.0170\n",
      "Epoch 32/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0993 - mae: 0.0886 - mse: 0.0156 - val_loss: 0.1061 - val_mae: 0.0954 - val_mse: 0.0171\n",
      "Epoch 33/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0992 - mae: 0.0885 - mse: 0.0158 - val_loss: 0.1100 - val_mae: 0.0993 - val_mse: 0.0187\n",
      "Epoch 34/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0986 - mae: 0.0878 - mse: 0.0155 - val_loss: 0.1072 - val_mae: 0.0965 - val_mse: 0.0177\n",
      "Epoch 35/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0962 - mae: 0.0854 - mse: 0.0148 - val_loss: 0.1053 - val_mae: 0.0945 - val_mse: 0.0173\n",
      "Epoch 36/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0975 - mae: 0.0868 - mse: 0.0151 - val_loss: 0.1074 - val_mae: 0.0967 - val_mse: 0.0181\n",
      "Epoch 37/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0974 - mae: 0.0867 - mse: 0.0151 - val_loss: 0.1072 - val_mae: 0.0964 - val_mse: 0.0178\n",
      "Epoch 38/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0957 - mae: 0.0849 - mse: 0.0145 - val_loss: 0.1127 - val_mae: 0.1019 - val_mse: 0.0200\n",
      "Epoch 39/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0953 - mae: 0.0845 - mse: 0.0144 - val_loss: 0.1070 - val_mae: 0.0962 - val_mse: 0.0177\n",
      "Epoch 40/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0942 - mae: 0.0834 - mse: 0.0142 - val_loss: 0.1054 - val_mae: 0.0946 - val_mse: 0.0172\n",
      "Epoch 41/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0950 - mae: 0.0842 - mse: 0.0143 - val_loss: 0.1069 - val_mae: 0.0961 - val_mse: 0.0174\n",
      "Epoch 42/100\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0935 - mae: 0.0826 - mse: 0.0138 - val_loss: 0.1053 - val_mae: 0.0945 - val_mse: 0.0172\n",
      "Epoch 43/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0930 - mae: 0.0822 - mse: 0.0139 - val_loss: 0.1069 - val_mae: 0.0961 - val_mse: 0.0176\n",
      "Epoch 44/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0934 - mae: 0.0825 - mse: 0.0139 - val_loss: 0.1112 - val_mae: 0.1003 - val_mse: 0.0189\n",
      "Epoch 45/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0931 - mae: 0.0823 - mse: 0.0139 - val_loss: 0.1078 - val_mae: 0.0969 - val_mse: 0.0175\n",
      "Fold 1 - MAE: 0.0945, MSE: 0.0173, R2: 0.9478\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/100\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.2089 - mae: 0.1855 - mse: 0.0793 - val_loss: 0.1526 - val_mae: 0.1299 - val_mse: 0.0287\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1516 - mae: 0.1296 - mse: 0.0295 - val_loss: 0.1457 - val_mae: 0.1244 - val_mse: 0.0251\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1392 - mae: 0.1185 - mse: 0.0251 - val_loss: 0.1340 - val_mae: 0.1140 - val_mse: 0.0221\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1323 - mae: 0.1129 - mse: 0.0231 - val_loss: 0.1277 - val_mae: 0.1088 - val_mse: 0.0202\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1275 - mae: 0.1091 - mse: 0.0219 - val_loss: 0.1265 - val_mae: 0.1086 - val_mse: 0.0205\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1249 - mae: 0.1074 - mse: 0.0216 - val_loss: 0.1219 - val_mae: 0.1049 - val_mse: 0.0189\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1208 - mae: 0.1042 - mse: 0.0206 - val_loss: 0.1219 - val_mae: 0.1057 - val_mse: 0.0195\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1188 - mae: 0.1030 - mse: 0.0199 - val_loss: 0.1230 - val_mae: 0.1075 - val_mse: 0.0202\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1166 - mae: 0.1014 - mse: 0.0197 - val_loss: 0.1192 - val_mae: 0.1044 - val_mse: 0.0189\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1151 - mae: 0.1005 - mse: 0.0194 - val_loss: 0.1186 - val_mae: 0.1043 - val_mse: 0.0194\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1139 - mae: 0.0998 - mse: 0.0191 - val_loss: 0.1131 - val_mae: 0.0992 - val_mse: 0.0179\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1122 - mae: 0.0986 - mse: 0.0188 - val_loss: 0.1148 - val_mae: 0.1014 - val_mse: 0.0184\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1117 - mae: 0.0984 - mse: 0.0187 - val_loss: 0.1157 - val_mae: 0.1027 - val_mse: 0.0192\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1093 - mae: 0.0965 - mse: 0.0181 - val_loss: 0.1162 - val_mae: 0.1035 - val_mse: 0.0191\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.1087 - mae: 0.0961 - mse: 0.0180 - val_loss: 0.1116 - val_mae: 0.0991 - val_mse: 0.0177\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1085 - mae: 0.0962 - mse: 0.0180 - val_loss: 0.1118 - val_mae: 0.0996 - val_mse: 0.0181\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1065 - mae: 0.0944 - mse: 0.0174 - val_loss: 0.1105 - val_mae: 0.0985 - val_mse: 0.0176\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1069 - mae: 0.0950 - mse: 0.0176 - val_loss: 0.1121 - val_mae: 0.1004 - val_mse: 0.0181\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1046 - mae: 0.0929 - mse: 0.0169 - val_loss: 0.1096 - val_mae: 0.0980 - val_mse: 0.0170\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1043 - mae: 0.0928 - mse: 0.0168 - val_loss: 0.1102 - val_mae: 0.0988 - val_mse: 0.0175\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1036 - mae: 0.0923 - mse: 0.0167 - val_loss: 0.1109 - val_mae: 0.0996 - val_mse: 0.0187\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1027 - mae: 0.0915 - mse: 0.0166 - val_loss: 0.1075 - val_mae: 0.0964 - val_mse: 0.0170\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1028 - mae: 0.0917 - mse: 0.0166 - val_loss: 0.1111 - val_mae: 0.1000 - val_mse: 0.0182\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1016 - mae: 0.0905 - mse: 0.0163 - val_loss: 0.1088 - val_mae: 0.0978 - val_mse: 0.0175\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1002 - mae: 0.0893 - mse: 0.0158 - val_loss: 0.1071 - val_mae: 0.0962 - val_mse: 0.0166\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1002 - mae: 0.0893 - mse: 0.0159 - val_loss: 0.1082 - val_mae: 0.0973 - val_mse: 0.0172\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1012 - mae: 0.0903 - mse: 0.0162 - val_loss: 0.1070 - val_mae: 0.0962 - val_mse: 0.0168\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0996 - mae: 0.0888 - mse: 0.0157 - val_loss: 0.1096 - val_mae: 0.0988 - val_mse: 0.0181\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.0979 - mae: 0.0871 - mse: 0.0152 - val_loss: 0.1114 - val_mae: 0.1006 - val_mse: 0.0188\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0996 - mae: 0.0888 - mse: 0.0157 - val_loss: 0.1123 - val_mae: 0.1016 - val_mse: 0.0186\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0988 - mae: 0.0880 - mse: 0.0155 - val_loss: 0.1109 - val_mae: 0.1002 - val_mse: 0.0186\n",
      "Epoch 32/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0967 - mae: 0.0860 - mse: 0.0150 - val_loss: 0.1074 - val_mae: 0.0967 - val_mse: 0.0175\n",
      "Epoch 33/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0975 - mae: 0.0868 - mse: 0.0151 - val_loss: 0.1092 - val_mae: 0.0985 - val_mse: 0.0186\n",
      "Epoch 34/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0985 - mae: 0.0878 - mse: 0.0154 - val_loss: 0.1079 - val_mae: 0.0973 - val_mse: 0.0177\n",
      "Epoch 35/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0965 - mae: 0.0858 - mse: 0.0149 - val_loss: 0.1070 - val_mae: 0.0963 - val_mse: 0.0169\n",
      "Fold 2 - MAE: 0.0962, MSE: 0.0166, R2: 0.9508\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/100\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.1965 - mae: 0.1730 - mse: 0.0654 - val_loss: 0.1545 - val_mae: 0.1316 - val_mse: 0.0289\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1507 - mae: 0.1284 - mse: 0.0289 - val_loss: 0.1437 - val_mae: 0.1220 - val_mse: 0.0249\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.1392 - mae: 0.1180 - mse: 0.0249 - val_loss: 0.1420 - val_mae: 0.1214 - val_mse: 0.0246\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.1328 - mae: 0.1127 - mse: 0.0231 - val_loss: 0.1367 - val_mae: 0.1172 - val_mse: 0.0238\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1288 - mae: 0.1097 - mse: 0.0220 - val_loss: 0.1387 - val_mae: 0.1201 - val_mse: 0.0242\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1259 - mae: 0.1078 - mse: 0.0216 - val_loss: 0.1385 - val_mae: 0.1208 - val_mse: 0.0240\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1230 - mae: 0.1057 - mse: 0.0208 - val_loss: 0.1377 - val_mae: 0.1207 - val_mse: 0.0233\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1195 - mae: 0.1029 - mse: 0.0200 - val_loss: 0.1345 - val_mae: 0.1182 - val_mse: 0.0234\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1187 - mae: 0.1029 - mse: 0.0198 - val_loss: 0.1311 - val_mae: 0.1155 - val_mse: 0.0223\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1157 - mae: 0.1004 - mse: 0.0193 - val_loss: 0.1257 - val_mae: 0.1106 - val_mse: 0.0213\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1127 - mae: 0.0980 - mse: 0.0184 - val_loss: 0.1183 - val_mae: 0.1038 - val_mse: 0.0194\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1114 - mae: 0.0971 - mse: 0.0181 - val_loss: 0.1205 - val_mae: 0.1065 - val_mse: 0.0203\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1099 - mae: 0.0960 - mse: 0.0178 - val_loss: 0.1283 - val_mae: 0.1146 - val_mse: 0.0225\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1104 - mae: 0.0969 - mse: 0.0180 - val_loss: 0.1195 - val_mae: 0.1061 - val_mse: 0.0199\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1078 - mae: 0.0946 - mse: 0.0174 - val_loss: 0.1179 - val_mae: 0.1049 - val_mse: 0.0196\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1076 - mae: 0.0947 - mse: 0.0173 - val_loss: 0.1202 - val_mae: 0.1074 - val_mse: 0.0205\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1066 - mae: 0.0939 - mse: 0.0171 - val_loss: 0.1158 - val_mae: 0.1032 - val_mse: 0.0194\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1049 - mae: 0.0925 - mse: 0.0166 - val_loss: 0.1156 - val_mae: 0.1033 - val_mse: 0.0190\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1035 - mae: 0.0912 - mse: 0.0163 - val_loss: 0.1146 - val_mae: 0.1024 - val_mse: 0.0191\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1030 - mae: 0.0910 - mse: 0.0162 - val_loss: 0.1169 - val_mae: 0.1050 - val_mse: 0.0197\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1028 - mae: 0.0909 - mse: 0.0163 - val_loss: 0.1100 - val_mae: 0.0982 - val_mse: 0.0181\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1018 - mae: 0.0901 - mse: 0.0159 - val_loss: 0.1157 - val_mae: 0.1041 - val_mse: 0.0194\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1008 - mae: 0.0891 - mse: 0.0157 - val_loss: 0.1127 - val_mae: 0.1011 - val_mse: 0.0187\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1009 - mae: 0.0893 - mse: 0.0158 - val_loss: 0.1118 - val_mae: 0.1003 - val_mse: 0.0186\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1004 - mae: 0.0889 - mse: 0.0157 - val_loss: 0.1142 - val_mae: 0.1028 - val_mse: 0.0193\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0990 - mae: 0.0876 - mse: 0.0152 - val_loss: 0.1113 - val_mae: 0.0999 - val_mse: 0.0184\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0988 - mae: 0.0875 - mse: 0.0152 - val_loss: 0.1130 - val_mae: 0.1018 - val_mse: 0.0186\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0982 - mae: 0.0869 - mse: 0.0151 - val_loss: 0.1127 - val_mae: 0.1015 - val_mse: 0.0192\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0975 - mae: 0.0863 - mse: 0.0149 - val_loss: 0.1115 - val_mae: 0.1003 - val_mse: 0.0186\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0969 - mae: 0.0858 - mse: 0.0147 - val_loss: 0.1118 - val_mae: 0.1007 - val_mse: 0.0184\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0959 - mae: 0.0848 - mse: 0.0146 - val_loss: 0.1126 - val_mae: 0.1015 - val_mse: 0.0192\n",
      "Fold 3 - MAE: 0.0982, MSE: 0.0181, R2: 0.9464\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/100\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.1985 - mae: 0.1749 - mse: 0.0709 - val_loss: 0.1622 - val_mae: 0.1394 - val_mse: 0.0332\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1468 - mae: 0.1247 - mse: 0.0272 - val_loss: 0.1439 - val_mae: 0.1225 - val_mse: 0.0262\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1345 - mae: 0.1138 - mse: 0.0231 - val_loss: 0.1413 - val_mae: 0.1212 - val_mse: 0.0262\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1298 - mae: 0.1103 - mse: 0.0221 - val_loss: 0.1366 - val_mae: 0.1176 - val_mse: 0.0245\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1258 - mae: 0.1073 - mse: 0.0213 - val_loss: 0.1526 - val_mae: 0.1346 - val_mse: 0.0316\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1217 - mae: 0.1042 - mse: 0.0201 - val_loss: 0.1353 - val_mae: 0.1182 - val_mse: 0.0253\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1197 - mae: 0.1030 - mse: 0.0198 - val_loss: 0.1416 - val_mae: 0.1253 - val_mse: 0.0279\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1190 - mae: 0.1030 - mse: 0.0199 - val_loss: 0.1381 - val_mae: 0.1225 - val_mse: 0.0270\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1157 - mae: 0.1004 - mse: 0.0191 - val_loss: 0.1415 - val_mae: 0.1265 - val_mse: 0.0303\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1153 - mae: 0.1005 - mse: 0.0190 - val_loss: 0.1225 - val_mae: 0.1080 - val_mse: 0.0223\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1118 - mae: 0.0975 - mse: 0.0181 - val_loss: 0.1199 - val_mae: 0.1059 - val_mse: 0.0214\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1087 - mae: 0.0949 - mse: 0.0172 - val_loss: 0.1225 - val_mae: 0.1090 - val_mse: 0.0233\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1116 - mae: 0.0982 - mse: 0.0183 - val_loss: 0.1189 - val_mae: 0.1057 - val_mse: 0.0215\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1077 - mae: 0.0946 - mse: 0.0171 - val_loss: 0.1204 - val_mae: 0.1075 - val_mse: 0.0221\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1066 - mae: 0.0939 - mse: 0.0172 - val_loss: 0.1193 - val_mae: 0.1067 - val_mse: 0.0217\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1063 - mae: 0.0938 - mse: 0.0170 - val_loss: 0.1178 - val_mae: 0.1054 - val_mse: 0.0215\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1050 - mae: 0.0927 - mse: 0.0166 - val_loss: 0.1202 - val_mae: 0.1080 - val_mse: 0.0223\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1037 - mae: 0.0915 - mse: 0.0162 - val_loss: 0.1143 - val_mae: 0.1023 - val_mse: 0.0201\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1037 - mae: 0.0918 - mse: 0.0163 - val_loss: 0.1166 - val_mae: 0.1048 - val_mse: 0.0211\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1027 - mae: 0.0910 - mse: 0.0162 - val_loss: 0.1155 - val_mae: 0.1038 - val_mse: 0.0207\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1027 - mae: 0.0910 - mse: 0.0163 - val_loss: 0.1147 - val_mae: 0.1031 - val_mse: 0.0204\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1016 - mae: 0.0901 - mse: 0.0160 - val_loss: 0.1160 - val_mae: 0.1045 - val_mse: 0.0210\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1007 - mae: 0.0893 - mse: 0.0156 - val_loss: 0.1144 - val_mae: 0.1031 - val_mse: 0.0204\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1015 - mae: 0.0902 - mse: 0.0161 - val_loss: 0.1159 - val_mae: 0.1047 - val_mse: 0.0212\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1009 - mae: 0.0897 - mse: 0.0159 - val_loss: 0.1144 - val_mae: 0.1033 - val_mse: 0.0203\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.0993 - mae: 0.0882 - mse: 0.0154 - val_loss: 0.1121 - val_mae: 0.1010 - val_mse: 0.0196\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0983 - mae: 0.0873 - mse: 0.0151 - val_loss: 0.1175 - val_mae: 0.1064 - val_mse: 0.0213\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0977 - mae: 0.0866 - mse: 0.0148 - val_loss: 0.1139 - val_mae: 0.1029 - val_mse: 0.0205\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0995 - mae: 0.0885 - mse: 0.0154 - val_loss: 0.1156 - val_mae: 0.1046 - val_mse: 0.0207\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0960 - mae: 0.0851 - mse: 0.0145 - val_loss: 0.1122 - val_mae: 0.1014 - val_mse: 0.0198\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0970 - mae: 0.0862 - mse: 0.0147 - val_loss: 0.1130 - val_mae: 0.1022 - val_mse: 0.0203\n",
      "Epoch 32/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0967 - mae: 0.0859 - mse: 0.0146 - val_loss: 0.1121 - val_mae: 0.1013 - val_mse: 0.0194\n",
      "Epoch 33/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0955 - mae: 0.0847 - mse: 0.0143 - val_loss: 0.1137 - val_mae: 0.1029 - val_mse: 0.0201\n",
      "Epoch 34/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0948 - mae: 0.0840 - mse: 0.0140 - val_loss: 0.1125 - val_mae: 0.1017 - val_mse: 0.0199\n",
      "Epoch 35/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0950 - mae: 0.0842 - mse: 0.0143 - val_loss: 0.1134 - val_mae: 0.1026 - val_mse: 0.0202\n",
      "Epoch 36/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0947 - mae: 0.0839 - mse: 0.0141 - val_loss: 0.1131 - val_mae: 0.1024 - val_mse: 0.0202\n",
      "Fold 4 - MAE: 0.1010, MSE: 0.0196, R2: 0.9422\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/100\n",
      "308/308 [==============================] - 1s 1ms/step - loss: 0.2063 - mae: 0.1833 - mse: 0.0806 - val_loss: 0.1684 - val_mae: 0.1466 - val_mse: 0.0337\n",
      "Epoch 2/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1466 - mae: 0.1257 - mse: 0.0280 - val_loss: 0.1516 - val_mae: 0.1315 - val_mse: 0.0281\n",
      "Epoch 3/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1367 - mae: 0.1173 - mse: 0.0245 - val_loss: 0.1380 - val_mae: 0.1192 - val_mse: 0.0247\n",
      "Epoch 4/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1313 - mae: 0.1131 - mse: 0.0231 - val_loss: 0.1351 - val_mae: 0.1174 - val_mse: 0.0242\n",
      "Epoch 5/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1251 - mae: 0.1079 - mse: 0.0214 - val_loss: 0.1277 - val_mae: 0.1109 - val_mse: 0.0224\n",
      "Epoch 6/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1220 - mae: 0.1056 - mse: 0.0206 - val_loss: 0.1237 - val_mae: 0.1077 - val_mse: 0.0212\n",
      "Epoch 7/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1207 - mae: 0.1050 - mse: 0.0205 - val_loss: 0.1179 - val_mae: 0.1026 - val_mse: 0.0198\n",
      "Epoch 8/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1178 - mae: 0.1028 - mse: 0.0197 - val_loss: 0.1202 - val_mae: 0.1056 - val_mse: 0.0209\n",
      "Epoch 9/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1170 - mae: 0.1027 - mse: 0.0198 - val_loss: 0.1156 - val_mae: 0.1016 - val_mse: 0.0197\n",
      "Epoch 10/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1155 - mae: 0.1017 - mse: 0.0194 - val_loss: 0.1200 - val_mae: 0.1064 - val_mse: 0.0208\n",
      "Epoch 11/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1136 - mae: 0.1002 - mse: 0.0191 - val_loss: 0.1149 - val_mae: 0.1018 - val_mse: 0.0194\n",
      "Epoch 12/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1120 - mae: 0.0990 - mse: 0.0187 - val_loss: 0.1193 - val_mae: 0.1064 - val_mse: 0.0206\n",
      "Epoch 13/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1114 - mae: 0.0988 - mse: 0.0186 - val_loss: 0.1151 - val_mae: 0.1026 - val_mse: 0.0199\n",
      "Epoch 14/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1090 - mae: 0.0965 - mse: 0.0180 - val_loss: 0.1126 - val_mae: 0.1003 - val_mse: 0.0190\n",
      "Epoch 15/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1081 - mae: 0.0959 - mse: 0.0178 - val_loss: 0.1095 - val_mae: 0.0975 - val_mse: 0.0183\n",
      "Epoch 16/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1076 - mae: 0.0956 - mse: 0.0177 - val_loss: 0.1115 - val_mae: 0.0997 - val_mse: 0.0192\n",
      "Epoch 17/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1071 - mae: 0.0953 - mse: 0.0175 - val_loss: 0.1102 - val_mae: 0.0986 - val_mse: 0.0182\n",
      "Epoch 18/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1049 - mae: 0.0933 - mse: 0.0171 - val_loss: 0.1139 - val_mae: 0.1024 - val_mse: 0.0193\n",
      "Epoch 19/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1044 - mae: 0.0930 - mse: 0.0170 - val_loss: 0.1103 - val_mae: 0.0990 - val_mse: 0.0189\n",
      "Epoch 20/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1038 - mae: 0.0924 - mse: 0.0167 - val_loss: 0.1101 - val_mae: 0.0988 - val_mse: 0.0182\n",
      "Epoch 21/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1041 - mae: 0.0929 - mse: 0.0170 - val_loss: 0.1110 - val_mae: 0.0999 - val_mse: 0.0190\n",
      "Epoch 22/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1030 - mae: 0.0919 - mse: 0.0167 - val_loss: 0.1099 - val_mae: 0.0988 - val_mse: 0.0189\n",
      "Epoch 23/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1018 - mae: 0.0908 - mse: 0.0163 - val_loss: 0.1115 - val_mae: 0.1005 - val_mse: 0.0189\n",
      "Epoch 24/100\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.1004 - mae: 0.0895 - mse: 0.0159 - val_loss: 0.1086 - val_mae: 0.0977 - val_mse: 0.0183\n",
      "Epoch 25/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1009 - mae: 0.0900 - mse: 0.0160 - val_loss: 0.1088 - val_mae: 0.0980 - val_mse: 0.0180\n",
      "Epoch 26/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1001 - mae: 0.0893 - mse: 0.0158 - val_loss: 0.1081 - val_mae: 0.0974 - val_mse: 0.0180\n",
      "Epoch 27/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1004 - mae: 0.0896 - mse: 0.0159 - val_loss: 0.1091 - val_mae: 0.0984 - val_mse: 0.0181\n",
      "Epoch 28/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0981 - mae: 0.0874 - mse: 0.0152 - val_loss: 0.1074 - val_mae: 0.0967 - val_mse: 0.0179\n",
      "Epoch 29/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0990 - mae: 0.0883 - mse: 0.0156 - val_loss: 0.1067 - val_mae: 0.0961 - val_mse: 0.0178\n",
      "Epoch 30/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0975 - mae: 0.0869 - mse: 0.0151 - val_loss: 0.1066 - val_mae: 0.0960 - val_mse: 0.0177\n",
      "Epoch 31/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0971 - mae: 0.0865 - mse: 0.0150 - val_loss: 0.1101 - val_mae: 0.0996 - val_mse: 0.0189\n",
      "Epoch 32/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0969 - mae: 0.0863 - mse: 0.0148 - val_loss: 0.1117 - val_mae: 0.1012 - val_mse: 0.0188\n",
      "Epoch 33/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0963 - mae: 0.0858 - mse: 0.0147 - val_loss: 0.1069 - val_mae: 0.0965 - val_mse: 0.0177\n",
      "Epoch 34/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0968 - mae: 0.0863 - mse: 0.0150 - val_loss: 0.1066 - val_mae: 0.0961 - val_mse: 0.0176\n",
      "Epoch 35/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0971 - mae: 0.0867 - mse: 0.0150 - val_loss: 0.1075 - val_mae: 0.0970 - val_mse: 0.0178\n",
      "Epoch 36/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0950 - mae: 0.0845 - mse: 0.0145 - val_loss: 0.1081 - val_mae: 0.0977 - val_mse: 0.0181\n",
      "Epoch 37/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0956 - mae: 0.0851 - mse: 0.0146 - val_loss: 0.1085 - val_mae: 0.0981 - val_mse: 0.0182\n",
      "Epoch 38/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0959 - mae: 0.0854 - mse: 0.0146 - val_loss: 0.1110 - val_mae: 0.1005 - val_mse: 0.0186\n",
      "Epoch 39/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0949 - mae: 0.0845 - mse: 0.0145 - val_loss: 0.1066 - val_mae: 0.0961 - val_mse: 0.0177\n",
      "Epoch 40/100\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.0930 - mae: 0.0826 - mse: 0.0139 - val_loss: 0.1068 - val_mae: 0.0963 - val_mse: 0.0175\n",
      "Fold 5 - MAE: 0.0960, MSE: 0.0177, R2: 0.9477\n",
      "\n",
      "Cross-Validation Results:\n",
      "--------------------------------------------------\n",
      "Average MAE: 0.0972 ± 0.0022\n",
      "Average MSE: 0.0179 ± 0.0010\n",
      "Average R2: 0.9470 ± 0.0028\n"
     ]
    }
   ],
   "source": [
    "cv_results = cv_saved_model_architecture(\n",
    "    saved_model_path='model_mecomep2.h5',\n",
    "    df=train_scaled_df,\n",
    "    target_column='r_value',\n",
    "    n_splits=5,\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print CV results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Average MAE: {cv_results['avg_mae']:.4f} ± {cv_results['std_mae']:.4f}\")\n",
    "print(f\"Average MSE: {cv_results['avg_mse']:.4f} ± {cv_results['std_mse']:.4f}\")\n",
    "print(f\"Average R2: {cv_results['avg_r2']:.4f} ± {cv_results['std_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GridSearch...\n",
      "\n",
      "Best parameters: {'C': 1, 'epsilon': 0.01}\n",
      "\n",
      "Performing cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 0.0956, MSE: 0.0176, R2: 0.9482, TOL90: 0.2191: 100%|██████████| 5/5 [00:44<00:00,  8.94s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'epsilon': [0.001, 0.01, 0.1, 0.5, 1, 2]\n",
    "}\n",
    "\n",
    "svr_results = train_model_with_cv_gridsearch(\n",
    "    df=train_scaled_df,\n",
    "    model=SVR(),\n",
    "    param_grid=svr_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GridSearch...\n",
      "\n",
      "Best parameters: {'alpha': 0.1}\n",
      "\n",
      "Performing cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 0.1208, MSE: 0.0250, R2: 0.9264, TOL90: 0.2566: 100%|██████████| 5/5 [00:00<00:00, 45.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "\n",
    "ridge_results = train_model_with_cv_gridsearch(\n",
    "    df=train_scaled_df,\n",
    "    model=Ridge(random_state=42),\n",
    "    param_grid=ridge_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate_model(data_df, features_dict, model_path, n_splits=5, batch_size=32):\n",
    "    \"\"\"\n",
    "    Load saved model and perform cross validation\n",
    "    \n",
    "    Args:\n",
    "        data_df: Pandas DataFrame containing the data\n",
    "        features_dict: Dictionary of features by category\n",
    "        model_path: Path to saved model file\n",
    "        n_splits: Number of CV folds\n",
    "        batch_size: Batch size for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics averaged across folds, including tol90\n",
    "    \"\"\"\n",
    "    # Load the saved model\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize feature arrays and dimensions\n",
    "    feature_arrays = {}\n",
    "    feature_dims = {}\n",
    "    \n",
    "    # Process each feature category\n",
    "    for category in ['chemical', 'time', 'process', 'model']:\n",
    "        available_features = [col for col in features_dict[category] \n",
    "                            if col in data_df.columns]\n",
    "        \n",
    "        if available_features:\n",
    "            feature_arrays[category] = data_df[available_features].values.astype(np.float32)\n",
    "            feature_dims[category] = len(available_features)\n",
    "        else:\n",
    "            feature_arrays[category] = np.zeros((len(data_df), 0), dtype=np.float32)\n",
    "            feature_dims[category] = 0\n",
    "    \n",
    "    # Prepare targets\n",
    "    targets = data_df['r_value'].values\n",
    "    \n",
    "    # Initialize KFold\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store metrics for each fold\n",
    "    fold_metrics = {\n",
    "        'mae': [],\n",
    "        'mse': [],\n",
    "        'rmse': [],\n",
    "        'r2': [],\n",
    "        'tol90': []  # Add tol90 to metrics\n",
    "    }\n",
    "    \n",
    "    # Cross validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(targets)):\n",
    "        # Prepare validation tensors for this fold\n",
    "        val_tensors = {\n",
    "            'chemical': torch.FloatTensor(feature_arrays['chemical'][val_idx]),\n",
    "            'time': torch.FloatTensor(feature_arrays['time'][val_idx]),\n",
    "            'process': torch.FloatTensor(feature_arrays['process'][val_idx]),\n",
    "            'model': torch.FloatTensor(feature_arrays['model'][val_idx])\n",
    "        }\n",
    "        \n",
    "        val_targets = torch.FloatTensor(targets[val_idx])\n",
    "        \n",
    "        # Create validation DataLoader\n",
    "        val_dataset = TensorDataset(\n",
    "            val_tensors['chemical'],\n",
    "            val_tensors['time'],\n",
    "            val_tensors['process'],\n",
    "            val_tensors['model'],\n",
    "            val_targets\n",
    "        )\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Evaluation for this fold\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_chem, batch_time, batch_proc, batch_model, batch_targets in val_loader:\n",
    "                outputs = model(batch_chem, batch_time, batch_proc, batch_model)\n",
    "                predictions.extend(outputs.numpy().flatten())\n",
    "                actuals.extend(batch_targets.numpy().flatten())\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        predictions = np.array(predictions)\n",
    "        actuals = np.array(actuals)\n",
    "        \n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "        \n",
    "        # Calculate tol90 (90th percentile of absolute errors)\n",
    "        abs_errors = np.abs(actuals - predictions)\n",
    "        tol90 = np.percentile(abs_errors, 90)\n",
    "        \n",
    "        fold_metrics['mae'].append(mae)\n",
    "        fold_metrics['mse'].append(mse)\n",
    "        fold_metrics['rmse'].append(rmse)\n",
    "        fold_metrics['r2'].append(r2)\n",
    "        fold_metrics['tol90'].append(tol90)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}, TOL90: {tol90:.4f}\")\n",
    "    \n",
    "    # Calculate and return average metrics\n",
    "    avg_metrics = {\n",
    "        'mae': np.mean(fold_metrics['mae']),\n",
    "        'mae_std': np.std(fold_metrics['mae']),\n",
    "        'mse': np.mean(fold_metrics['mse']),\n",
    "        'mse_std': np.std(fold_metrics['mse']), \n",
    "        'rmse': np.mean(fold_metrics['rmse']),\n",
    "        'rmse_std': np.std(fold_metrics['rmse']),\n",
    "        'r2': np.mean(fold_metrics['r2']),\n",
    "        'r2_std': np.std(fold_metrics['r2']),\n",
    "        'tol90': np.mean(fold_metrics['tol90']),  # Add average tol90\n",
    "        'tol90_std': np.std(fold_metrics['tol90'])  # Add tol90 standard deviation\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAverage Metrics across folds:\")\n",
    "    print(f\"MAE: {avg_metrics['mae']:.4f} ± {avg_metrics['mae_std']:.4f}\")\n",
    "    print(f\"MSE: {avg_metrics['mse']:.4f} ± {avg_metrics['mse_std']:.4f}\")\n",
    "    print(f\"RMSE: {avg_metrics['rmse']:.4f} ± {avg_metrics['rmse_std']:.4f}\")\n",
    "    print(f\"R2: {avg_metrics['r2']:.4f} ± {avg_metrics['r2_std']:.4f}\")\n",
    "    print(f\"TOL90: {avg_metrics['tol90']:.4f} ± {avg_metrics['tol90_std']:.4f}\")\n",
    "    \n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the features for each branch\n",
    "features = [col for col in df.columns if col not in ['r_value', 'steel_family', 'steel_grade']]\n",
    "features_dict = {\n",
    "   'time': [col for col in features if 'time' in col.lower()], \n",
    "   'chemical': ['pct_al', 'pct_b', 'pct_c', 'pct_cr', 'pct_mn', 'pct_n', 'pct_nb', 'pct_si', 'pct_ti', 'pct_v', 'mfia_coil_frac_fer', 'mfia_et1_frac_fer', 'mfia_et2_frac_fer'],\n",
    "   'model': [\"rm\", \"ag\", \"a80\", \"n_value\"]\n",
    "}\n",
    "features_dict['process'] = [col for col in features if col not in features_dict['time'] and col not in features_dict['chemical']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchSteelRegressor(nn.Module):\n",
    "    def __init__(self, chemical_dim, time_dim, process_dim, model_dim, hidden_units=64, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        # Track which branches are active\n",
    "        self.has_chemical = chemical_dim > 0\n",
    "        self.has_time = time_dim > 0\n",
    "        self.has_process = process_dim > 0\n",
    "        self.has_model = model_dim > 0\n",
    "        \n",
    "        # Count active branches\n",
    "        self.active_branches = sum([self.has_chemical, self.has_time, self.has_process, self.has_model])\n",
    "        \n",
    "        # Adjust hidden units for each branch\n",
    "        self.branch_hidden = min(hidden_units, max(16, hidden_units // 2))\n",
    "        \n",
    "        # Creating branch\n",
    "        def create_branch(input_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(input_dim, self.branch_hidden),\n",
    "                nn.BatchNorm1d(self.branch_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "        \n",
    "        # Only create branches that have features\n",
    "        if self.has_chemical:\n",
    "            self.chemical_branch = create_branch(chemical_dim)\n",
    "        if self.has_time:\n",
    "            self.time_branch = create_branch(time_dim)\n",
    "        if self.has_process:\n",
    "            self.process_branch = create_branch(process_dim)\n",
    "        if self.has_model:\n",
    "            self.model_branch = create_branch(model_dim)\n",
    "        \n",
    "        # Combined input dimension based on active branches only\n",
    "        combined_dim = self.branch_hidden * self.active_branches\n",
    "        \n",
    "        # Final layers after concatenation\n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, chemical, time, process, model):\n",
    "        features = []\n",
    "        # Only process branches that have features\n",
    "        if self.has_chemical:\n",
    "            if chemical.dim() == 1:\n",
    "                chemical = chemical.unsqueeze(0)\n",
    "            features.append(self.chemical_branch(chemical))\n",
    "        \n",
    "        if self.has_time:\n",
    "            if time.dim() == 1:\n",
    "                time = time.unsqueeze(0)\n",
    "            features.append(self.time_branch(time))\n",
    "        \n",
    "        if self.has_process:\n",
    "            if process.dim() == 1:\n",
    "                process = process.unsqueeze(0)\n",
    "            features.append(self.process_branch(process))\n",
    "        \n",
    "        if self.has_model:\n",
    "            if model.dim() == 1:\n",
    "                model = model.unsqueeze(0)\n",
    "            features.append(self.model_branch(model))\n",
    "        \n",
    "        # Concatenate only active features\n",
    "        combined = torch.cat(features, dim=1) if len(features) > 1 else features[0]\n",
    "        return self.final_layers(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_regular(df, features_dict, num_epochs, hyperparameters, use_l2=False):\n",
    "    batch_size = hyperparameters['batch_size']\n",
    "    \n",
    "    # Initialize feature arrays and dimensions\n",
    "    feature_arrays = {}\n",
    "    feature_dims = {}\n",
    "    \n",
    "    # Process each feature category\n",
    "    for category in ['chemical', 'time', 'process', 'model']:\n",
    "        available_features = [col for col in features_dict[category] \n",
    "                            if col in df.columns]\n",
    "        \n",
    "        if available_features:\n",
    "            feature_arrays[category] = df[available_features].values.astype(np.float32)\n",
    "            feature_dims[category] = len(available_features)\n",
    "        else:\n",
    "            feature_arrays[category] = np.zeros((len(df), 0), dtype=np.float32)\n",
    "            feature_dims[category] = 0\n",
    "    \n",
    "    # Prepare targets\n",
    "    targets = df['r_value'].values\n",
    "    \n",
    "    # Split data\n",
    "    split_data = train_test_split(\n",
    "        feature_arrays['chemical'],\n",
    "        feature_arrays['time'],\n",
    "        feature_arrays['process'],\n",
    "        feature_arrays['model'],\n",
    "        targets,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    (X_train_chem, X_test_chem, X_train_time, X_test_time, \n",
    "     X_train_proc, X_test_proc, X_train_model, X_test_model, \n",
    "     y_train, y_test) = split_data\n",
    "    \n",
    "    # Convert to tensors\n",
    "    train_tensors = {\n",
    "        'chemical': torch.FloatTensor(X_train_chem),\n",
    "        'time': torch.FloatTensor(X_train_time),\n",
    "        'process': torch.FloatTensor(X_train_proc),\n",
    "        'model': torch.FloatTensor(X_train_model)\n",
    "    }\n",
    "    \n",
    "    test_tensors = {\n",
    "        'chemical': torch.FloatTensor(X_test_chem),\n",
    "        'time': torch.FloatTensor(X_test_time),\n",
    "        'process': torch.FloatTensor(X_test_proc),\n",
    "        'model': torch.FloatTensor(X_test_model)\n",
    "    }\n",
    "    \n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    y_test_tensor = torch.FloatTensor(y_test)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(\n",
    "        train_tensors['chemical'],\n",
    "        train_tensors['time'],\n",
    "        train_tensors['process'],\n",
    "        train_tensors['model'],\n",
    "        y_train_tensor\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MultiBranchSteelRegressor(\n",
    "        chemical_dim=feature_dims['chemical'],\n",
    "        time_dim=feature_dims['time'],\n",
    "        process_dim=feature_dims['process'],\n",
    "        model_dim=feature_dims['model'],\n",
    "        hidden_units=hyperparameters['hidden_units'],\n",
    "        dropout_rate=hyperparameters['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    if use_l2:\n",
    "        weight_decay = 0.001\n",
    "    else:\n",
    "        weight_decay = 0.0\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=weight_decay)\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_chem, batch_time, batch_proc, batch_model, batch_targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_chem, batch_time, batch_proc, batch_model)\n",
    "            loss = criterion(outputs, batch_targets.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(\n",
    "            test_tensors['chemical'],\n",
    "            test_tensors['time'],\n",
    "            test_tensors['process'],\n",
    "            test_tensors['model']\n",
    "        )\n",
    "        test_loss = criterion(y_pred, y_test_tensor.unsqueeze(1)).item()\n",
    "        y_pred_np = y_pred.numpy().flatten()\n",
    "        r2 = r2_score(y_test, y_pred_np)\n",
    "        mae = mean_absolute_error(y_test, y_pred_np)\n",
    "        mse = mean_squared_error(y_test, y_pred_np)\n",
    "        \n",
    "        metrics = {\n",
    "            'r2_score': r2,\n",
    "            'mae': mae,\n",
    "            'mse': mse,\n",
    "            'test_loss': test_loss\n",
    "        }\n",
    "        print(f\"Evaluation - Test Loss: {test_loss:.4f}, R2: {r2:.4f}\")\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 1e-3],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'hidden_units': [64, 128, 256],\n",
    "    'dropout_rate': [0, 0.2]\n",
    "}\n",
    "grid = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1149\n",
      "Epoch [20/100], Loss: 0.1068\n",
      "Epoch [30/100], Loss: 0.0995\n",
      "Epoch [40/100], Loss: 0.0983\n",
      "Epoch [50/100], Loss: 0.0949\n",
      "Epoch [60/100], Loss: 0.0948\n",
      "Epoch [70/100], Loss: 0.0930\n",
      "Epoch [80/100], Loss: 0.0909\n",
      "Epoch [90/100], Loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   2%|▏         | 1/54 [03:36<3:11:39, 216.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0891\n",
      "Evaluation - Test Loss: 0.0910, R2: 0.9505\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1158\n",
      "Epoch [20/100], Loss: 0.1055\n",
      "Epoch [30/100], Loss: 0.0999\n",
      "Epoch [40/100], Loss: 0.0975\n",
      "Epoch [50/100], Loss: 0.0946\n",
      "Epoch [60/100], Loss: 0.0931\n",
      "Epoch [70/100], Loss: 0.0909\n",
      "Epoch [80/100], Loss: 0.0920\n",
      "Epoch [90/100], Loss: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   4%|▎         | 2/54 [06:50<2:56:07, 203.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0887\n",
      "Evaluation - Test Loss: 0.0890, R2: 0.9522\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1161\n",
      "Epoch [20/100], Loss: 0.1073\n",
      "Epoch [30/100], Loss: 0.0997\n",
      "Epoch [40/100], Loss: 0.0970\n",
      "Epoch [50/100], Loss: 0.0967\n",
      "Epoch [60/100], Loss: 0.0938\n",
      "Epoch [70/100], Loss: 0.0934\n",
      "Epoch [80/100], Loss: 0.0911\n",
      "Epoch [90/100], Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   6%|▌         | 3/54 [10:03<2:48:52, 198.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0887\n",
      "Evaluation - Test Loss: 0.0897, R2: 0.9533\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1149\n",
      "Epoch [20/100], Loss: 0.1036\n",
      "Epoch [30/100], Loss: 0.1002\n",
      "Epoch [40/100], Loss: 0.0965\n",
      "Epoch [50/100], Loss: 0.0934\n",
      "Epoch [60/100], Loss: 0.0924\n",
      "Epoch [70/100], Loss: 0.0897\n",
      "Epoch [80/100], Loss: 0.0901\n",
      "Epoch [90/100], Loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   7%|▋         | 4/54 [13:22<2:45:25, 198.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0864\n",
      "Evaluation - Test Loss: 0.0904, R2: 0.9519\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1159\n",
      "Epoch [20/100], Loss: 0.1044\n",
      "Epoch [30/100], Loss: 0.1000\n",
      "Epoch [40/100], Loss: 0.0962\n",
      "Epoch [50/100], Loss: 0.0928\n",
      "Epoch [60/100], Loss: 0.0917\n",
      "Epoch [70/100], Loss: 0.0896\n",
      "Epoch [80/100], Loss: 0.0897\n",
      "Epoch [90/100], Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   9%|▉         | 5/54 [16:57<2:47:00, 204.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0866\n",
      "Evaluation - Test Loss: 0.0923, R2: 0.9492\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1156\n",
      "Epoch [20/100], Loss: 0.1045\n",
      "Epoch [30/100], Loss: 0.1004\n",
      "Epoch [40/100], Loss: 0.0959\n",
      "Epoch [50/100], Loss: 0.0945\n",
      "Epoch [60/100], Loss: 0.0917\n",
      "Epoch [70/100], Loss: 0.0902\n",
      "Epoch [80/100], Loss: 0.0899\n",
      "Epoch [90/100], Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  11%|█         | 6/54 [20:18<2:42:48, 203.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0865\n",
      "Evaluation - Test Loss: 0.0943, R2: 0.9473\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1164\n",
      "Epoch [20/100], Loss: 0.1035\n",
      "Epoch [30/100], Loss: 0.0985\n",
      "Epoch [40/100], Loss: 0.0951\n",
      "Epoch [50/100], Loss: 0.0930\n",
      "Epoch [60/100], Loss: 0.0909\n",
      "Epoch [70/100], Loss: 0.0895\n",
      "Epoch [80/100], Loss: 0.0886\n",
      "Epoch [90/100], Loss: 0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  13%|█▎        | 7/54 [23:51<2:41:44, 206.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0860\n",
      "Evaluation - Test Loss: 0.0898, R2: 0.9498\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1148\n",
      "Epoch [20/100], Loss: 0.1047\n",
      "Epoch [30/100], Loss: 0.0991\n",
      "Epoch [40/100], Loss: 0.0960\n",
      "Epoch [50/100], Loss: 0.0931\n",
      "Epoch [60/100], Loss: 0.0912\n",
      "Epoch [70/100], Loss: 0.0892\n",
      "Epoch [80/100], Loss: 0.0897\n",
      "Epoch [90/100], Loss: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  15%|█▍        | 8/54 [27:28<2:40:53, 209.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0863\n",
      "Evaluation - Test Loss: 0.0903, R2: 0.9513\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1139\n",
      "Epoch [20/100], Loss: 0.1038\n",
      "Epoch [30/100], Loss: 0.0977\n",
      "Epoch [40/100], Loss: 0.0951\n",
      "Epoch [50/100], Loss: 0.0923\n",
      "Epoch [60/100], Loss: 0.0920\n",
      "Epoch [70/100], Loss: 0.0888\n",
      "Epoch [80/100], Loss: 0.0887\n",
      "Epoch [90/100], Loss: 0.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  17%|█▋        | 9/54 [31:04<2:38:50, 211.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0846\n",
      "Evaluation - Test Loss: 0.0904, R2: 0.9496\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1555\n",
      "Epoch [20/100], Loss: 0.1427\n",
      "Epoch [30/100], Loss: 0.1378\n",
      "Epoch [40/100], Loss: 0.1350\n",
      "Epoch [50/100], Loss: 0.1306\n",
      "Epoch [60/100], Loss: 0.1288\n",
      "Epoch [70/100], Loss: 0.1274\n",
      "Epoch [80/100], Loss: 0.1261\n",
      "Epoch [90/100], Loss: 0.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  19%|█▊        | 10/54 [34:35<2:35:13, 211.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1239\n",
      "Evaluation - Test Loss: 0.1087, R2: 0.9356\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1559\n",
      "Epoch [20/100], Loss: 0.1443\n",
      "Epoch [30/100], Loss: 0.1367\n",
      "Epoch [40/100], Loss: 0.1364\n",
      "Epoch [50/100], Loss: 0.1343\n",
      "Epoch [60/100], Loss: 0.1303\n",
      "Epoch [70/100], Loss: 0.1293\n",
      "Epoch [80/100], Loss: 0.1301\n",
      "Epoch [90/100], Loss: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  20%|██        | 11/54 [38:00<2:30:05, 209.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1253\n",
      "Evaluation - Test Loss: 0.1119, R2: 0.9306\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1557\n",
      "Epoch [20/100], Loss: 0.1440\n",
      "Epoch [30/100], Loss: 0.1380\n",
      "Epoch [40/100], Loss: 0.1349\n",
      "Epoch [50/100], Loss: 0.1334\n",
      "Epoch [60/100], Loss: 0.1310\n",
      "Epoch [70/100], Loss: 0.1299\n",
      "Epoch [80/100], Loss: 0.1279\n",
      "Epoch [90/100], Loss: 0.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  22%|██▏       | 12/54 [41:22<2:25:06, 207.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1277\n",
      "Evaluation - Test Loss: 0.1153, R2: 0.9281\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1544\n",
      "Epoch [20/100], Loss: 0.1400\n",
      "Epoch [30/100], Loss: 0.1362\n",
      "Epoch [40/100], Loss: 0.1314\n",
      "Epoch [50/100], Loss: 0.1311\n",
      "Epoch [60/100], Loss: 0.1296\n",
      "Epoch [70/100], Loss: 0.1267\n",
      "Epoch [80/100], Loss: 0.1255\n",
      "Epoch [90/100], Loss: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  24%|██▍       | 13/54 [44:52<2:22:08, 208.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1242\n",
      "Evaluation - Test Loss: 0.0948, R2: 0.9487\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1531\n",
      "Epoch [20/100], Loss: 0.1394\n",
      "Epoch [30/100], Loss: 0.1326\n",
      "Epoch [40/100], Loss: 0.1318\n",
      "Epoch [50/100], Loss: 0.1289\n",
      "Epoch [60/100], Loss: 0.1271\n",
      "Epoch [70/100], Loss: 0.1267\n",
      "Epoch [80/100], Loss: 0.1239\n",
      "Epoch [90/100], Loss: 0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  26%|██▌       | 14/54 [48:22<2:19:05, 208.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1226\n",
      "Evaluation - Test Loss: 0.1021, R2: 0.9418\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1553\n",
      "Epoch [20/100], Loss: 0.1390\n",
      "Epoch [30/100], Loss: 0.1357\n",
      "Epoch [40/100], Loss: 0.1316\n",
      "Epoch [50/100], Loss: 0.1295\n",
      "Epoch [60/100], Loss: 0.1286\n",
      "Epoch [70/100], Loss: 0.1272\n",
      "Epoch [80/100], Loss: 0.1241\n",
      "Epoch [90/100], Loss: 0.1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  28%|██▊       | 15/54 [51:50<2:15:34, 208.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1219\n",
      "Evaluation - Test Loss: 0.1063, R2: 0.9360\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1511\n",
      "Epoch [20/100], Loss: 0.1389\n",
      "Epoch [30/100], Loss: 0.1330\n",
      "Epoch [40/100], Loss: 0.1283\n",
      "Epoch [50/100], Loss: 0.1258\n",
      "Epoch [60/100], Loss: 0.1241\n",
      "Epoch [70/100], Loss: 0.1224\n",
      "Epoch [80/100], Loss: 0.1209\n",
      "Epoch [90/100], Loss: 0.1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  30%|██▉       | 16/54 [55:29<2:14:00, 211.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1193\n",
      "Evaluation - Test Loss: 0.1005, R2: 0.9432\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1553\n",
      "Epoch [20/100], Loss: 0.1387\n",
      "Epoch [30/100], Loss: 0.1332\n",
      "Epoch [40/100], Loss: 0.1288\n",
      "Epoch [50/100], Loss: 0.1252\n",
      "Epoch [60/100], Loss: 0.1273\n",
      "Epoch [70/100], Loss: 0.1240\n",
      "Epoch [80/100], Loss: 0.1213\n",
      "Epoch [90/100], Loss: 0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  31%|███▏      | 17/54 [59:07<2:11:46, 213.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1220\n",
      "Evaluation - Test Loss: 0.0993, R2: 0.9445\n",
      "Evaluating hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1517\n",
      "Epoch [20/100], Loss: 0.1361\n",
      "Epoch [30/100], Loss: 0.1323\n",
      "Epoch [40/100], Loss: 0.1293\n",
      "Epoch [50/100], Loss: 0.1284\n",
      "Epoch [60/100], Loss: 0.1258\n",
      "Epoch [70/100], Loss: 0.1262\n",
      "Epoch [80/100], Loss: 0.1239\n",
      "Epoch [90/100], Loss: 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  33%|███▎      | 18/54 [1:02:47<2:09:11, 215.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1203\n",
      "Evaluation - Test Loss: 0.1086, R2: 0.9336\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1111\n",
      "Epoch [20/100], Loss: 0.1022\n",
      "Epoch [30/100], Loss: 0.0964\n",
      "Epoch [40/100], Loss: 0.0925\n",
      "Epoch [50/100], Loss: 0.0902\n",
      "Epoch [60/100], Loss: 0.0887\n",
      "Epoch [70/100], Loss: 0.0863\n",
      "Epoch [80/100], Loss: 0.0836\n",
      "Epoch [90/100], Loss: 0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  35%|███▌      | 19/54 [1:04:32<1:46:25, 182.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0809\n",
      "Evaluation - Test Loss: 0.0889, R2: 0.9534\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1096\n",
      "Epoch [20/100], Loss: 0.1005\n",
      "Epoch [30/100], Loss: 0.0964\n",
      "Epoch [40/100], Loss: 0.0937\n",
      "Epoch [50/100], Loss: 0.0904\n",
      "Epoch [60/100], Loss: 0.0876\n",
      "Epoch [70/100], Loss: 0.0865\n",
      "Epoch [80/100], Loss: 0.0840\n",
      "Epoch [90/100], Loss: 0.0832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  37%|███▋      | 20/54 [1:06:19<1:30:25, 159.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0820\n",
      "Evaluation - Test Loss: 0.0921, R2: 0.9515\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1106\n",
      "Epoch [20/100], Loss: 0.1021\n",
      "Epoch [30/100], Loss: 0.0950\n",
      "Epoch [40/100], Loss: 0.0922\n",
      "Epoch [50/100], Loss: 0.0902\n",
      "Epoch [60/100], Loss: 0.0875\n",
      "Epoch [70/100], Loss: 0.0864\n",
      "Epoch [80/100], Loss: 0.0843\n",
      "Epoch [90/100], Loss: 0.0815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  39%|███▉      | 21/54 [1:08:05<1:18:56, 143.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0818\n",
      "Evaluation - Test Loss: 0.0920, R2: 0.9504\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1089\n",
      "Epoch [20/100], Loss: 0.0991\n",
      "Epoch [30/100], Loss: 0.0932\n",
      "Epoch [40/100], Loss: 0.0894\n",
      "Epoch [50/100], Loss: 0.0879\n",
      "Epoch [60/100], Loss: 0.0847\n",
      "Epoch [70/100], Loss: 0.0823\n",
      "Epoch [80/100], Loss: 0.0821\n",
      "Epoch [90/100], Loss: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  41%|████      | 22/54 [1:09:57<1:11:27, 133.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0787\n",
      "Evaluation - Test Loss: 0.0907, R2: 0.9496\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1126\n",
      "Epoch [20/100], Loss: 0.0999\n",
      "Epoch [30/100], Loss: 0.0956\n",
      "Epoch [40/100], Loss: 0.0906\n",
      "Epoch [50/100], Loss: 0.0865\n",
      "Epoch [60/100], Loss: 0.0855\n",
      "Epoch [70/100], Loss: 0.0830\n",
      "Epoch [80/100], Loss: 0.0803\n",
      "Epoch [90/100], Loss: 0.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  43%|████▎     | 23/54 [1:11:47<1:05:32, 126.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0781\n",
      "Evaluation - Test Loss: 0.0913, R2: 0.9482\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1079\n",
      "Epoch [20/100], Loss: 0.0990\n",
      "Epoch [30/100], Loss: 0.0935\n",
      "Epoch [40/100], Loss: 0.0904\n",
      "Epoch [50/100], Loss: 0.0868\n",
      "Epoch [60/100], Loss: 0.0871\n",
      "Epoch [70/100], Loss: 0.0840\n",
      "Epoch [80/100], Loss: 0.0811\n",
      "Epoch [90/100], Loss: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  44%|████▍     | 24/54 [1:13:36<1:00:47, 121.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0781\n",
      "Evaluation - Test Loss: 0.0946, R2: 0.9462\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1068\n",
      "Epoch [20/100], Loss: 0.0986\n",
      "Epoch [30/100], Loss: 0.0928\n",
      "Epoch [40/100], Loss: 0.0890\n",
      "Epoch [50/100], Loss: 0.0872\n",
      "Epoch [60/100], Loss: 0.0832\n",
      "Epoch [70/100], Loss: 0.0810\n",
      "Epoch [80/100], Loss: 0.0789\n",
      "Epoch [90/100], Loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  46%|████▋     | 25/54 [1:15:32<57:56, 119.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0778\n",
      "Evaluation - Test Loss: 0.0900, R2: 0.9520\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1093\n",
      "Epoch [20/100], Loss: 0.0982\n",
      "Epoch [30/100], Loss: 0.0956\n",
      "Epoch [40/100], Loss: 0.0895\n",
      "Epoch [50/100], Loss: 0.0872\n",
      "Epoch [60/100], Loss: 0.0840\n",
      "Epoch [70/100], Loss: 0.0825\n",
      "Epoch [80/100], Loss: 0.0812\n",
      "Epoch [90/100], Loss: 0.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  48%|████▊     | 26/54 [1:17:27<55:13, 118.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0766\n",
      "Evaluation - Test Loss: 0.0924, R2: 0.9507\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1090\n",
      "Epoch [20/100], Loss: 0.0976\n",
      "Epoch [30/100], Loss: 0.0929\n",
      "Epoch [40/100], Loss: 0.0905\n",
      "Epoch [50/100], Loss: 0.0853\n",
      "Epoch [60/100], Loss: 0.0826\n",
      "Epoch [70/100], Loss: 0.0828\n",
      "Epoch [80/100], Loss: 0.0788\n",
      "Epoch [90/100], Loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  50%|█████     | 27/54 [1:19:22<52:51, 117.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0781\n",
      "Evaluation - Test Loss: 0.0931, R2: 0.9486\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1545\n",
      "Epoch [20/100], Loss: 0.1379\n",
      "Epoch [30/100], Loss: 0.1280\n",
      "Epoch [40/100], Loss: 0.1241\n",
      "Epoch [50/100], Loss: 0.1258\n",
      "Epoch [60/100], Loss: 0.1212\n",
      "Epoch [70/100], Loss: 0.1204\n",
      "Epoch [80/100], Loss: 0.1187\n",
      "Epoch [90/100], Loss: 0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  52%|█████▏    | 28/54 [1:21:14<50:13, 115.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1161\n",
      "Evaluation - Test Loss: 0.0974, R2: 0.9470\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1550\n",
      "Epoch [20/100], Loss: 0.1396\n",
      "Epoch [30/100], Loss: 0.1309\n",
      "Epoch [40/100], Loss: 0.1266\n",
      "Epoch [50/100], Loss: 0.1259\n",
      "Epoch [60/100], Loss: 0.1236\n",
      "Epoch [70/100], Loss: 0.1203\n",
      "Epoch [80/100], Loss: 0.1205\n",
      "Epoch [90/100], Loss: 0.1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  54%|█████▎    | 29/54 [1:23:07<47:53, 114.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1174\n",
      "Evaluation - Test Loss: 0.0937, R2: 0.9507\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1579\n",
      "Epoch [20/100], Loss: 0.1410\n",
      "Epoch [30/100], Loss: 0.1305\n",
      "Epoch [40/100], Loss: 0.1267\n",
      "Epoch [50/100], Loss: 0.1263\n",
      "Epoch [60/100], Loss: 0.1231\n",
      "Epoch [70/100], Loss: 0.1220\n",
      "Epoch [80/100], Loss: 0.1202\n",
      "Epoch [90/100], Loss: 0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  56%|█████▌    | 30/54 [1:25:00<45:42, 114.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1157\n",
      "Evaluation - Test Loss: 0.0932, R2: 0.9503\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1555\n",
      "Epoch [20/100], Loss: 0.1359\n",
      "Epoch [30/100], Loss: 0.1298\n",
      "Epoch [40/100], Loss: 0.1240\n",
      "Epoch [50/100], Loss: 0.1230\n",
      "Epoch [60/100], Loss: 0.1193\n",
      "Epoch [70/100], Loss: 0.1182\n",
      "Epoch [80/100], Loss: 0.1166\n",
      "Epoch [90/100], Loss: 0.1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  57%|█████▋    | 31/54 [1:26:56<44:01, 114.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1137\n",
      "Evaluation - Test Loss: 0.0926, R2: 0.9513\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1542\n",
      "Epoch [20/100], Loss: 0.1377\n",
      "Epoch [30/100], Loss: 0.1285\n",
      "Epoch [40/100], Loss: 0.1230\n",
      "Epoch [50/100], Loss: 0.1202\n",
      "Epoch [60/100], Loss: 0.1192\n",
      "Epoch [70/100], Loss: 0.1145\n",
      "Epoch [80/100], Loss: 0.1147\n",
      "Epoch [90/100], Loss: 0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  59%|█████▉    | 32/54 [1:28:52<42:12, 115.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1141\n",
      "Evaluation - Test Loss: 0.0928, R2: 0.9494\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1490\n",
      "Epoch [20/100], Loss: 0.1348\n",
      "Epoch [30/100], Loss: 0.1277\n",
      "Epoch [40/100], Loss: 0.1257\n",
      "Epoch [50/100], Loss: 0.1219\n",
      "Epoch [60/100], Loss: 0.1198\n",
      "Epoch [70/100], Loss: 0.1173\n",
      "Epoch [80/100], Loss: 0.1163\n",
      "Epoch [90/100], Loss: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  61%|██████    | 33/54 [1:30:49<40:29, 115.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1139\n",
      "Evaluation - Test Loss: 0.0963, R2: 0.9465\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1525\n",
      "Epoch [20/100], Loss: 0.1317\n",
      "Epoch [30/100], Loss: 0.1247\n",
      "Epoch [40/100], Loss: 0.1225\n",
      "Epoch [50/100], Loss: 0.1173\n",
      "Epoch [60/100], Loss: 0.1156\n",
      "Epoch [70/100], Loss: 0.1137\n",
      "Epoch [80/100], Loss: 0.1126\n",
      "Epoch [90/100], Loss: 0.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  63%|██████▎   | 34/54 [1:32:52<39:20, 118.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1118\n",
      "Evaluation - Test Loss: 0.0910, R2: 0.9521\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1512\n",
      "Epoch [20/100], Loss: 0.1326\n",
      "Epoch [30/100], Loss: 0.1256\n",
      "Epoch [40/100], Loss: 0.1208\n",
      "Epoch [50/100], Loss: 0.1184\n",
      "Epoch [60/100], Loss: 0.1163\n",
      "Epoch [70/100], Loss: 0.1138\n",
      "Epoch [80/100], Loss: 0.1105\n",
      "Epoch [90/100], Loss: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  65%|██████▍   | 35/54 [1:34:57<38:00, 120.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1109\n",
      "Evaluation - Test Loss: 0.0990, R2: 0.9429\n",
      "Evaluating hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1514\n",
      "Epoch [20/100], Loss: 0.1352\n",
      "Epoch [30/100], Loss: 0.1251\n",
      "Epoch [40/100], Loss: 0.1226\n",
      "Epoch [50/100], Loss: 0.1202\n",
      "Epoch [60/100], Loss: 0.1164\n",
      "Epoch [70/100], Loss: 0.1141\n",
      "Epoch [80/100], Loss: 0.1128\n",
      "Epoch [90/100], Loss: 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  67%|██████▋   | 36/54 [1:37:01<36:19, 121.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1110\n",
      "Evaluation - Test Loss: 0.0931, R2: 0.9521\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1033\n",
      "Epoch [20/100], Loss: 0.0951\n",
      "Epoch [30/100], Loss: 0.0904\n",
      "Epoch [40/100], Loss: 0.0867\n",
      "Epoch [50/100], Loss: 0.0845\n",
      "Epoch [60/100], Loss: 0.0834\n",
      "Epoch [70/100], Loss: 0.0797\n",
      "Epoch [80/100], Loss: 0.0785\n",
      "Epoch [90/100], Loss: 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  69%|██████▊   | 37/54 [1:38:03<29:18, 103.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0752\n",
      "Evaluation - Test Loss: 0.0906, R2: 0.9511\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1021\n",
      "Epoch [20/100], Loss: 0.0963\n",
      "Epoch [30/100], Loss: 0.0908\n",
      "Epoch [40/100], Loss: 0.0888\n",
      "Epoch [50/100], Loss: 0.0844\n",
      "Epoch [60/100], Loss: 0.0811\n",
      "Epoch [70/100], Loss: 0.0794\n",
      "Epoch [80/100], Loss: 0.0780\n",
      "Epoch [90/100], Loss: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  70%|███████   | 38/54 [1:39:06<24:19, 91.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0749\n",
      "Evaluation - Test Loss: 0.0924, R2: 0.9507\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1025\n",
      "Epoch [20/100], Loss: 0.0955\n",
      "Epoch [30/100], Loss: 0.0902\n",
      "Epoch [40/100], Loss: 0.0864\n",
      "Epoch [50/100], Loss: 0.0837\n",
      "Epoch [60/100], Loss: 0.0807\n",
      "Epoch [70/100], Loss: 0.0793\n",
      "Epoch [80/100], Loss: 0.0782\n",
      "Epoch [90/100], Loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  72%|███████▏  | 39/54 [1:40:08<20:39, 82.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0746\n",
      "Evaluation - Test Loss: 0.0970, R2: 0.9480\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1048\n",
      "Epoch [20/100], Loss: 0.0956\n",
      "Epoch [30/100], Loss: 0.0905\n",
      "Epoch [40/100], Loss: 0.0876\n",
      "Epoch [50/100], Loss: 0.0850\n",
      "Epoch [60/100], Loss: 0.0797\n",
      "Epoch [70/100], Loss: 0.0778\n",
      "Epoch [80/100], Loss: 0.0758\n",
      "Epoch [90/100], Loss: 0.0739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  74%|███████▍  | 40/54 [1:41:13<18:01, 77.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0719\n",
      "Evaluation - Test Loss: 0.0988, R2: 0.9418\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1044\n",
      "Epoch [20/100], Loss: 0.0922\n",
      "Epoch [30/100], Loss: 0.0887\n",
      "Epoch [40/100], Loss: 0.0865\n",
      "Epoch [50/100], Loss: 0.0832\n",
      "Epoch [60/100], Loss: 0.0788\n",
      "Epoch [70/100], Loss: 0.0774\n",
      "Epoch [80/100], Loss: 0.0743\n",
      "Epoch [90/100], Loss: 0.0737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  76%|███████▌  | 41/54 [1:42:17<15:53, 73.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0716\n",
      "Evaluation - Test Loss: 0.0965, R2: 0.9466\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 128, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1038\n",
      "Epoch [20/100], Loss: 0.0976\n",
      "Epoch [30/100], Loss: 0.0903\n",
      "Epoch [40/100], Loss: 0.0852\n",
      "Epoch [50/100], Loss: 0.0847\n",
      "Epoch [60/100], Loss: 0.0798\n",
      "Epoch [70/100], Loss: 0.0783\n",
      "Epoch [80/100], Loss: 0.0782\n",
      "Epoch [90/100], Loss: 0.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  78%|███████▊  | 42/54 [1:43:21<14:05, 70.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0725\n",
      "Evaluation - Test Loss: 0.0940, R2: 0.9496\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.0999\n",
      "Epoch [20/100], Loss: 0.0943\n",
      "Epoch [30/100], Loss: 0.0893\n",
      "Epoch [40/100], Loss: 0.0842\n",
      "Epoch [50/100], Loss: 0.0816\n",
      "Epoch [60/100], Loss: 0.0805\n",
      "Epoch [70/100], Loss: 0.0761\n",
      "Epoch [80/100], Loss: 0.0752\n",
      "Epoch [90/100], Loss: 0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  80%|███████▉  | 43/54 [1:44:31<12:55, 70.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0713\n",
      "Evaluation - Test Loss: 0.0939, R2: 0.9492\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1024\n",
      "Epoch [20/100], Loss: 0.0938\n",
      "Epoch [30/100], Loss: 0.0887\n",
      "Epoch [40/100], Loss: 0.0866\n",
      "Epoch [50/100], Loss: 0.0817\n",
      "Epoch [60/100], Loss: 0.0799\n",
      "Epoch [70/100], Loss: 0.0780\n",
      "Epoch [80/100], Loss: 0.0743\n",
      "Epoch [90/100], Loss: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  81%|████████▏ | 44/54 [1:45:43<11:48, 70.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0699\n",
      "Evaluation - Test Loss: 0.0912, R2: 0.9495\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0, 'hidden_units': 256, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1003\n",
      "Epoch [20/100], Loss: 0.0942\n",
      "Epoch [30/100], Loss: 0.0878\n",
      "Epoch [40/100], Loss: 0.0856\n",
      "Epoch [50/100], Loss: 0.0817\n",
      "Epoch [60/100], Loss: 0.0769\n",
      "Epoch [70/100], Loss: 0.0762\n",
      "Epoch [80/100], Loss: 0.0741\n",
      "Epoch [90/100], Loss: 0.0716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  83%|████████▎ | 45/54 [1:46:52<10:31, 70.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0700\n",
      "Evaluation - Test Loss: 0.0912, R2: 0.9518\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1569\n",
      "Epoch [20/100], Loss: 0.1386\n",
      "Epoch [30/100], Loss: 0.1269\n",
      "Epoch [40/100], Loss: 0.1242\n",
      "Epoch [50/100], Loss: 0.1186\n",
      "Epoch [60/100], Loss: 0.1176\n",
      "Epoch [70/100], Loss: 0.1164\n",
      "Epoch [80/100], Loss: 0.1151\n",
      "Epoch [90/100], Loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  85%|████████▌ | 46/54 [1:47:56<09:08, 68.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1139\n",
      "Evaluation - Test Loss: 0.0909, R2: 0.9523\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1545\n",
      "Epoch [20/100], Loss: 0.1359\n",
      "Epoch [30/100], Loss: 0.1261\n",
      "Epoch [40/100], Loss: 0.1227\n",
      "Epoch [50/100], Loss: 0.1214\n",
      "Epoch [60/100], Loss: 0.1211\n",
      "Epoch [70/100], Loss: 0.1174\n",
      "Epoch [80/100], Loss: 0.1160\n",
      "Epoch [90/100], Loss: 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  87%|████████▋ | 47/54 [1:49:02<07:53, 67.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1150\n",
      "Evaluation - Test Loss: 0.0937, R2: 0.9502\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 64, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1563\n",
      "Epoch [20/100], Loss: 0.1365\n",
      "Epoch [30/100], Loss: 0.1278\n",
      "Epoch [40/100], Loss: 0.1250\n",
      "Epoch [50/100], Loss: 0.1183\n",
      "Epoch [60/100], Loss: 0.1165\n",
      "Epoch [70/100], Loss: 0.1151\n",
      "Epoch [80/100], Loss: 0.1149\n",
      "Epoch [90/100], Loss: 0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  89%|████████▉ | 48/54 [1:50:07<06:41, 66.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1128\n",
      "Evaluation - Test Loss: 0.0924, R2: 0.9522\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1580\n",
      "Epoch [20/100], Loss: 0.1367\n",
      "Epoch [30/100], Loss: 0.1234\n",
      "Epoch [40/100], Loss: 0.1199\n",
      "Epoch [50/100], Loss: 0.1192\n",
      "Epoch [60/100], Loss: 0.1153\n",
      "Epoch [70/100], Loss: 0.1130\n",
      "Epoch [80/100], Loss: 0.1125\n",
      "Epoch [90/100], Loss: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  91%|█████████ | 49/54 [1:51:16<05:37, 67.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1092\n",
      "Evaluation - Test Loss: 0.0941, R2: 0.9495\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1515\n",
      "Epoch [20/100], Loss: 0.1331\n",
      "Epoch [30/100], Loss: 0.1250\n",
      "Epoch [40/100], Loss: 0.1195\n",
      "Epoch [50/100], Loss: 0.1155\n",
      "Epoch [60/100], Loss: 0.1134\n",
      "Epoch [70/100], Loss: 0.1135\n",
      "Epoch [80/100], Loss: 0.1114\n",
      "Epoch [90/100], Loss: 0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  93%|█████████▎| 50/54 [1:52:25<04:31, 68.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1093\n",
      "Evaluation - Test Loss: 0.0894, R2: 0.9528\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 128, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1572\n",
      "Epoch [20/100], Loss: 0.1392\n",
      "Epoch [30/100], Loss: 0.1278\n",
      "Epoch [40/100], Loss: 0.1221\n",
      "Epoch [50/100], Loss: 0.1182\n",
      "Epoch [60/100], Loss: 0.1131\n",
      "Epoch [70/100], Loss: 0.1118\n",
      "Epoch [80/100], Loss: 0.1129\n",
      "Epoch [90/100], Loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  94%|█████████▍| 51/54 [1:53:34<03:24, 68.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1090\n",
      "Evaluation - Test Loss: 0.0891, R2: 0.9541\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.1}\n",
      "Epoch [10/100], Loss: 0.1524\n",
      "Epoch [20/100], Loss: 0.1367\n",
      "Epoch [30/100], Loss: 0.1227\n",
      "Epoch [40/100], Loss: 0.1182\n",
      "Epoch [50/100], Loss: 0.1145\n",
      "Epoch [60/100], Loss: 0.1127\n",
      "Epoch [70/100], Loss: 0.1088\n",
      "Epoch [80/100], Loss: 0.1090\n",
      "Epoch [90/100], Loss: 0.1075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  96%|█████████▋| 52/54 [1:54:48<02:19, 69.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1047\n",
      "Evaluation - Test Loss: 0.0920, R2: 0.9510\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.01}\n",
      "Epoch [10/100], Loss: 0.1567\n",
      "Epoch [20/100], Loss: 0.1324\n",
      "Epoch [30/100], Loss: 0.1239\n",
      "Epoch [40/100], Loss: 0.1192\n",
      "Epoch [50/100], Loss: 0.1121\n",
      "Epoch [60/100], Loss: 0.1131\n",
      "Epoch [70/100], Loss: 0.1089\n",
      "Epoch [80/100], Loss: 0.1095\n",
      "Epoch [90/100], Loss: 0.1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:  98%|█████████▊| 53/54 [1:56:03<01:11, 71.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1078\n",
      "Evaluation - Test Loss: 0.0941, R2: 0.9507\n",
      "Evaluating hyperparameters: {'batch_size': 64, 'dropout_rate': 0.2, 'hidden_units': 256, 'learning_rate': 0.001}\n",
      "Epoch [10/100], Loss: 0.1476\n",
      "Epoch [20/100], Loss: 0.1319\n",
      "Epoch [30/100], Loss: 0.1223\n",
      "Epoch [40/100], Loss: 0.1159\n",
      "Epoch [50/100], Loss: 0.1152\n",
      "Epoch [60/100], Loss: 0.1132\n",
      "Epoch [70/100], Loss: 0.1114\n",
      "Epoch [80/100], Loss: 0.1086\n",
      "Epoch [90/100], Loss: 0.1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress: 100%|██████████| 54/54 [1:57:19<00:00, 130.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1060\n",
      "Evaluation - Test Loss: 0.0911, R2: 0.9521\n",
      "Best parameters found: {'batch_size': 32, 'dropout_rate': 0, 'hidden_units': 64, 'learning_rate': 0.1}\n",
      "Best MAE: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "best_params = None\n",
    "best_results = {'mae': float('inf')}\n",
    "\n",
    "for params in tqdm(grid, desc=\"Grid Search Progress\", leave=True):\n",
    "    print(f\"Evaluating hyperparameters: {params}\")\n",
    "    \n",
    "    model, metrics = train_model_regular(train_scaled_df, features_dict, num_epochs, params)\n",
    "    mae = metrics['mae']\n",
    "    \n",
    "    if best_params is None or mae < best_results['mae']:\n",
    "        best_results = {\n",
    "            'mae': mae,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best MAE: {best_results['mae']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform cross validation\n",
    "# metrics = load_and_evaluate_model(\n",
    "#     data_df=train_scaled_df,\n",
    "#     features_dict=features_dict,\n",
    "#     model_path='branchmlp.pth',\n",
    "#     n_splits=5,\n",
    "#     batch_size=32\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
